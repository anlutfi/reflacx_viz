{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation tools for REFLACX data\n",
    "\n",
    "This notebook provides sample usage of the tools made for visualization of REFLACX data.\n",
    "\n",
    "REFLACX data is available [here](https://physionet.org/content/reflacx-xray-localization/1.0.0/). The dataset's code is available in [this repo](https://github.com/ricbl/eyetracking).\n",
    "\n",
    "MIMIC-CXR data, REFLACX parent dataset, is available [here](https://physionet.org/content/mimic-cxr/2.0.0/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data should be already downloaded, see get_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_meta_path = 'full_meta.json' # if file doesnt exist, it will be created\n",
    "reflacx_dir = \"../data/reflacx\"\n",
    "mimic_dir = \"../data/mimic/reflacx_imgs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metadata import Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFLACX's original data structure divides the trials by id, each one corresponding to a MIMIC-CXR x-ray. More than one id can be associated to the same x-ray. So, the first step is loading reflacx metadata grouped by x-ray, making each xray contain references to each REFLACX observation that references it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = Metadata(reflacx_dir, mimic_dir, full_meta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plot\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List first MIMIC-CXR dicom ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.list_dicom_ids(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dcm = '' # choose one from last cell's result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all REFLACX ids associated with the chosen dicom id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.list_reflacx_ids(sample_dcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = '' # choose one from last cell's result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a REFLACX datapoint and display its mimic-cxr corresponding x-ray image\n",
    "the datapoint is encapsulated by an object of class ReflacxSample, defined in reflacx_sample.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = metadata.get_sample(sample_dcm, sample_id)\n",
    "datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xray = datapoint.get_dicom_img()\n",
    "plot.imshow(xray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chest Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = datapoint.get_chest_bounding_box()\n",
    "bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawn over original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = datapoint.canvas()\n",
    "canvas = cv2.rectangle(canvas,\n",
    "                       (bb['xmin'], bb['ymin']),\n",
    "                       (bb['xmax'], bb['ymax']),\n",
    "                       (0, 255, 0),\n",
    "                       40)\n",
    "\n",
    "plot.imshow(canvas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.imshow(datapoint.get_cropped_chest_img(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcriptions\n",
    "\n",
    "For these visualisation tools, it made sense to split the transcription into period separated sentences, each with its start and end timestamps. Eye-tracking fixations are linked to their corresponding sentence.\n",
    "\n",
    "All fixations made before the first sentence are attributed to a sentence called \"_pre_transcript\".\n",
    "All made after last sentence are attributed to \"_post_transcript\".\n",
    "\n",
    "This division needs review, as the radiologist could be already making the first observation before saying it, wrongly associating fixations to pre transcript, where they could be referring to the first sentence.\n",
    "\n",
    "There needs to be a clustering technique based on timestamp to distinguish better. Or maybe just dropping pre-transcript altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = datapoint.get_timed_sentences()\n",
    "(sentences[1].keys(),\n",
    " sentences[1]['start_t'],\n",
    " sentences[1]['end_t'],\n",
    " sentences[1]['sentence'],\n",
    " sentences[1]['fixations'][0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawing fixations for each transcription sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixations_by_sentence = datapoint.draw_fixations_by_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot.figure(figsize=(25, 50))\n",
    "\n",
    "for i, key in enumerate(fixations_by_sentence.keys(), 1):\n",
    "    sp = f.add_subplot(6, 2, i)\n",
    "    sp.title.set_text(key)\n",
    "    plot.axis('off')\n",
    "    plot.imshow(fixations_by_sentence[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate heatmap for all fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = datapoint.get_heatmap()\n",
    "chest_hm = datapoint.get_heatmap(chest_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot.figure(figsize=(25, 20))\n",
    "_131 = f.add_subplot(2, 3, 1)\n",
    "_131.title.set_text('HEATMAP')\n",
    "plot.axis('off')\n",
    "plot.imshow(hm, cmap='jet')\n",
    "_132 = f.add_subplot(2, 3, 2)\n",
    "_132.title.set_text('X-RAY')\n",
    "plot.axis('off')\n",
    "plot.imshow(xray)\n",
    "_133 = f.add_subplot(2, 3, 3)\n",
    "_133.title.set_text('OVERLAY')\n",
    "plot.axis('off')\n",
    "plot.imshow(xray * hm)\n",
    "\n",
    "chest = datapoint.get_cropped_chest_img()\n",
    "\n",
    "_231 = f.add_subplot(2, 3, 4)\n",
    "_231.title.set_text('CHEST-ONLY HEATMAP')\n",
    "plot.axis('off')\n",
    "plot.imshow(chest_hm, cmap='jet')\n",
    "_232 = f.add_subplot(2, 3, 5)\n",
    "_232.title.set_text('CHEST-ONLY X-RAY')\n",
    "plot.axis('off')\n",
    "plot.imshow(chest)\n",
    "_233 = f.add_subplot(2, 3, 6)\n",
    "_233.title.set_text('CHEST-ONLY OVERLAY')\n",
    "plot.axis('off')\n",
    "plot.imshow((chest * chest_hm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmaps grouped by transcription sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hms = datapoint.get_heatmaps_by_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot.figure(figsize=(25, 50))\n",
    "\n",
    "for i, hm in enumerate(hms, 1):\n",
    "    sp = f.add_subplot(6, 2, i)\n",
    "    sp.title.set_text('{}    {}  -  {}'.format(hm['title'], str(hm['start_t']), str(hm['end_t'])))\n",
    "    plot.axis('off')\n",
    "    plot.imshow(hm['img'] * xray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellips = datapoint.get_anomaly_ellipses()\n",
    "ellips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_imgs = datapoint.draw_anomaly_ellipses()\n",
    "anom_imgs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(anom_imgs, 1):\n",
    "    sp = f.add_subplot(2, 4, i)\n",
    "    sp.title.set_text(key)\n",
    "    plot.axis('off')\n",
    "    plot.imshow(anom_imgs[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
